{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b8d2c30-3d8a-4d7e-99e9-988e07db8574",
   "metadata": {},
   "source": [
    "\n",
    "1. Load and preprocess the tabular data, excluding the columns you mentioned as unnecessary.\n",
    "2. Resize and preprocess the images to feed into a convolutional neural network (CNN) for feature extraction.\n",
    "3. Concatenate the CNN-extracted image features with the tabular data.\n",
    "4. Encode the `gaze` labels using `LabelEncoder`.\n",
    "5. Train the LightGBM model on the combined dataset.\n",
    "6. Validate the model on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a5c9a6-9fd7-4380-b5b1-5102418c2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cad3fc7-253c-4a64-8286-d2febccdcbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "### Step 1: Preprocessing Tabular Data\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.models import Model\n",
    "train_dir='C:\\Datasets\\labels_and_features_TRAIN.csv'\n",
    "valid_dir='C:\\Datasets\\labels_and_features_VAL.csv'\n",
    "\n",
    "# Load the dataset\n",
    "train_df = pd.read_csv(train_dir)\n",
    "validate_df = pd.read_csv(valid_dir)\n",
    "\n",
    "# Drop unwanted columns\n",
    "columns_to_drop = ['teacherID', 'gaze0', 'gaze1', 'gaze2']\n",
    "train_df = train_df.drop(columns=columns_to_drop)\n",
    "validate_df = validate_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Encode the 'gaze' column\n",
    "le = LabelEncoder()\n",
    "train_df['gaze'] = le.fit_transform(train_df['gaze'])\n",
    "validate_df['gaze'] = le.transform(validate_df['gaze'])\n",
    "\n",
    "# Separate features and labels\n",
    "X_train_tabular = train_df.drop('gaze', axis=1)\n",
    "y_train = train_df['gaze']\n",
    "X_validate_tabular = validate_df.drop('gaze', axis=1)\n",
    "y_validate = validate_df['gaze']\n",
    "\n",
    "\n",
    "### Step 2: Preprocessing Images\n",
    "\n",
    "\n",
    "# Load and preprocess images\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded = np.expand_dims(img_array, axis=0)\n",
    "    return preprocess_input(img_array_expanded)\n",
    "\n",
    "# Extract features using a pre-trained CNN\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "def extract_features(img_paths):\n",
    "    all_features = []\n",
    "    for img_path in img_paths:\n",
    "        img_features = model.predict(load_and_preprocess_image(img_path))\n",
    "        img_features_flatten = img_features.flatten()\n",
    "        all_features.append(img_features_flatten)\n",
    "    return np.array(all_features)\n",
    "\n",
    "train_img_paths = [f'C:\\\\Datasets\\\\Talis_frames15_v2\\\\{img_id}' for img_id in train_df['imgID']]\n",
    "validate_img_paths = [f'C:\\\\Datasets\\\\Talis_frames15_v2\\\\{img_id}' for img_id in validate_df['imgID']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f060d4-ba53-444f-aba2-d0e071010efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract image features\n",
    "X_train_images = extract_features(train_img_paths)\n",
    "X_validate_images = extract_features(validate_img_paths)\n",
    "\n",
    "\n",
    "### Step 3: Combine Image Features with Tabular Data\n",
    "\n",
    "\n",
    "# Concatenate tabular features with image features\n",
    "X_train_combined = np.concatenate((X_train_tabular, X_train_images), axis=1)[:100]\n",
    "X_validate_combined = np.concatenate((X_validate_tabular, X_validate_images), axis=1)\n",
    "\n",
    "\n",
    "### Step 4: Train LightGBM Model\n",
    "\n",
    "\n",
    "# Create the LightGBM dataset\n",
    "d_train = lgb.Dataset(X_train_combined, label=y_train)\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(np.unique(y_train)),\n",
    "    'learning_rate': 0.1,\n",
    "    'metric': 'multi_logloss'\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "lgb_model = lgb.train(params, d_train, num_boost_round=100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77f6c2fd-7365-4d5a-a10c-e6b726519147",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Predict on validation set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlgb_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_validate_combined)\n\u001b[0;32m      3\u001b[0m y_pred_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m### Step 5: Validate the Model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Calculate the accuracy\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict on validation set\n",
    "y_pred = lgb_model.predict(X_validate_combined)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "\n",
    "### Step 5: Validate the Model\n",
    "\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_validate, y_pred_labels)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d2a33-ba38-4a73-b352-370cc21002a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
