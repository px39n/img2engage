{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46381935-b093-4570-8f92-50309cebb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=32\n",
    "data_path = r\"C:\\Datasets\\Engagement\\VIDEO000\\00000\"  # Provide your data path here\n",
    "ckpt_dir = r\"C:\\Datasets\\Engagement\\checkpoints\\epoch_6.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd5af8b-2f9a-4e46-9b84-fc7cb0a91fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "class GazeDataset(Dataset):\n",
    "    def __init__(self,  data_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file.\n",
    "            data_path (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "        \"\"\"\n",
    "        dir_path =os.path.join(data_path,\"image_original\")\n",
    "        png_files = [f for f in os.listdir(dir_path) if f.endswith('.png')]\n",
    "        self.data_frame = pd.DataFrame(png_files, columns=['imgID'])\n",
    "        print(dir_path)\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        # Create a dictionary mapping each unique gaze value to a unique integer\n",
    "        self.gaze_to_int ={3: 0, 2: 1, 1: 0, 4: 1}\n",
    "        self.num_classes = 2\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.data_path+\"\\image_original\", self.data_frame['imgID'][idx])  # Assuming imgID is in the first column\n",
    "        image = Image.open(img_name)\n",
    "        head_name = os.path.join(self.data_path+\"\\predict_head\", self.data_frame['imgID'][idx])\n",
    "        head = Image.open(head_name)\n",
    "        gaze_name = os.path.join(self.data_path+\"\\predict_heatmap\", self.data_frame['imgID'][idx])\n",
    "        gaze_img = Image.open(gaze_name) \n",
    "        skeleton_name = os.path.join(self.data_path+\"\\image_skeleton\", self.data_frame['imgID'][idx].replace(\".png\",\"_rendered.png\"))\n",
    "        skeleton_img = Image.open(skeleton_name)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            head = transform2(head)\n",
    "            gaze_img = transform2(gaze_img)\n",
    "            skeleton_img = transform2(skeleton_img) \n",
    "            \n",
    " \n",
    "        return image, head, gaze_img, skeleton_img, self.data_frame['imgID'][idx]\n",
    "\n",
    "# Create datasets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "\n",
    "model = models.resnet18(weights=\"ResNet18_Weights.DEFAULT\")\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model.conv1 = nn.Conv2d(10, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "checkpoint = torch.load(ckpt_dir)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "\n",
    "predicted_dataset = GazeDataset(data_path=data_path, transform=transform)  \n",
    "# Randomly pick 3 images from the validation dataset\n",
    "\n",
    "data = []\n",
    "df=pd.DataFrame(columns=['imgID',\"prediction\"])\n",
    "\n",
    "for idx in tqdm(range(len(predicted_dataset))):\n",
    "    image, depth, gaze, skeleton_img, basename = predicted_dataset[idx]\n",
    "    input_tensor = torch.cat([image.unsqueeze(0), depth.unsqueeze(0), gaze.unsqueeze(0), skeleton_img.unsqueeze(0)], dim=1)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad(): \n",
    "        output = model(input_tensor)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "    data.append({'imgID': basename, 'prediction': predicted.item()})\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "    # Plotting\n",
    "    #print( f\"Prediction: {predicted.item()}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
