{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b8d2c30-3d8a-4d7e-99e9-988e07db8574",
   "metadata": {},
   "source": [
    "\n",
    "1. Load and preprocess the tabular data, excluding the columns you mentioned as unnecessary.\n",
    "2. Resize and preprocess the images to feed into a convolutional neural network (CNN) for feature extraction.\n",
    "3. Concatenate the CNN-extracted image features with the tabular data.\n",
    "4. Encode the `gaze` labels using `LabelEncoder`.\n",
    "5. Train the LightGBM model on the combined dataset.\n",
    "6. Validate the model on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad3fc7-253c-4a64-8286-d2febccdcbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f060d4-ba53-444f-aba2-d0e071010efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isxzl\\anaconda3\\envs\\engagement\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\isxzl\\anaconda3\\envs\\engagement\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "train_dir='C:\\Datasets\\labels_and_features_TRAIN.csv'\n",
    "valid_dir='C:\\Datasets\\labels_and_features_VAL.csv'\n",
    "\n",
    "# Load the dataset\n",
    "train_df = pd.read_csv(train_dir)\n",
    "validate_df = pd.read_csv(valid_dir)\n",
    "\n",
    "# Drop unwanted columns and separate features and labels\n",
    "columns_to_drop = ['teacherID', 'gaze0', 'gaze1', 'gaze2', 'imgID']\n",
    "X_train_tabular = train_df.drop(columns=columns_to_drop + ['gaze'])\n",
    "y_train = train_df['gaze']\n",
    "X_validate_tabular = validate_df.drop(columns=columns_to_drop + ['gaze'])\n",
    "y_validate = validate_df['gaze']\n",
    "\n",
    "# Encode the 'gaze' labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_validate = le.transform(y_validate)\n",
    "\n",
    "# Define a transformation for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Define a custom dataset to load images\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = f'{self.img_dir}\\\\{self.dataframe.iloc[idx][\"imgID\"]}'\n",
    "        image = Image.open(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# Instantiate datasets\n",
    "train_img_dir = 'C:\\\\Datasets\\\\Talis_frames15_v2'\n",
    "train_dataset = ImageDataset(train_df, train_img_dir, transform)\n",
    "validate_dataset = ImageDataset(validate_df, train_img_dir, transform)\n",
    "\n",
    "# Use a pre-trained model for feature extraction\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Remove the top layer (fully connected layers)\n",
    "modules = list(model.children())[:-1]\n",
    "model = torch.nn.Sequential(*modules)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310fc1f6-a276-4983-a29e-c16be7e91993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████████████████████████████████████████████████████| 77/77 [10:34<00:00,  8.24s/batch]\n",
      "Extracting features: 100%|██████████████████████████████████████████████████████████| 19/19 [02:33<00:00,  8.06s/batch]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to extract features from a dataset\n",
    "from tqdm import tqdm\n",
    "def extract_features(dataset):\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    features = []\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(loader, desc=\"Extracting features\", unit=\"batch\"):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.view(outputs.size(0), -1)  # Flatten the features\n",
    "            features.append(outputs.cpu().numpy())\n",
    "\n",
    "    return np.vstack(features)\n",
    "\n",
    "\n",
    "# Extract features for both training and validation sets\n",
    "X_train_images = extract_features(train_dataset)\n",
    "X_validate_images = extract_features(validate_dataset)\n",
    "\n",
    "# Concatenate tabular features with image features\n",
    "X_train_combined = np.concatenate((X_train_tabular, X_train_images), axis=1)\n",
    "X_validate_combined = np.concatenate((X_validate_tabular, X_validate_images), axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f6c2fd-7365-4d5a-a10c-e6b726519147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.161589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 539871\n",
      "[LightGBM] [Info] Number of data points in the train set: 2451, number of used features: 2118\n",
      "[LightGBM] [Info] Start training from score -3.527585\n",
      "[LightGBM] [Info] Start training from score -1.169618\n",
      "[LightGBM] [Info] Start training from score -0.461472\n",
      "[LightGBM] [Info] Start training from score -3.513792\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "# Train the LightGBM model\n",
    "d_train = lgb.Dataset(X_train_combined, label=y_train)\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(np.unique(y_train)),\n",
    "    'learning_rate': 0.1,\n",
    "    'metric': 'multi_logloss'\n",
    "}\n",
    "lgb_model = lgb.train(params, d_train, num_boost_round=100)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = lgb_model.predict(X_validate_combined)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d2a33-ba38-4a73-b352-370cc21002a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_validate, y_pred_labels)\n",
    "print('Accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
